{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from configparser import ConfigParser\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config(filename='database.ini', section='postgresql'):\n",
    "    # create a parser\n",
    "    parser = ConfigParser()\n",
    "    # read config file\n",
    "    parser.read(filename)\n",
    "\n",
    "    # get section, default to postgresql\n",
    "    db = {}\n",
    "    if parser.has_section(section):\n",
    "        params = parser.items(section)\n",
    "        for param in params:\n",
    "            db[param[0]] = param[1]\n",
    "    else:\n",
    "        raise Exception('Section {0} not found in the {1} file'.format(section, filename))\n",
    "\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dic=config()\n",
    "\n",
    "connect = \"postgresql+psycopg2://%s:%s@%s:%s/%s\" % (\n",
    "param_dic['user'],\n",
    "param_dic['password'],\n",
    "param_dic['host'],\n",
    "param_dic['port'],\n",
    "param_dic['database']\n",
    ")\n",
    "\n",
    "engine=create_engine(connect, echo=False)\n",
    "\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_query=\"select timestamp,close,high,low,open,trades,turnover,volume,vwap from bitmex as bt where  bt.timestamp >= date '2018-01-01' \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= connection.execute(my_query).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data,columns=['timestamp','close','high','low','open','trades','turnover','volume','vwap'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>trades</th>\n",
       "      <th>turnover</th>\n",
       "      <th>volume</th>\n",
       "      <th>vwap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00+05:00</td>\n",
       "      <td>13925.5</td>\n",
       "      <td>13925.5</td>\n",
       "      <td>13892.5</td>\n",
       "      <td>13909.5</td>\n",
       "      <td>93</td>\n",
       "      <td>934907830</td>\n",
       "      <td>129990</td>\n",
       "      <td>13904.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 00:01:00+05:00</td>\n",
       "      <td>13914.0</td>\n",
       "      <td>13938.5</td>\n",
       "      <td>13910.0</td>\n",
       "      <td>13925.5</td>\n",
       "      <td>143</td>\n",
       "      <td>3584829106</td>\n",
       "      <td>499411</td>\n",
       "      <td>13931.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 00:02:00+05:00</td>\n",
       "      <td>13960.5</td>\n",
       "      <td>13979.5</td>\n",
       "      <td>13914.0</td>\n",
       "      <td>13914.0</td>\n",
       "      <td>196</td>\n",
       "      <td>2916432935</td>\n",
       "      <td>406988</td>\n",
       "      <td>13956.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 00:03:00+05:00</td>\n",
       "      <td>13972.0</td>\n",
       "      <td>13972.0</td>\n",
       "      <td>13950.0</td>\n",
       "      <td>13960.5</td>\n",
       "      <td>76</td>\n",
       "      <td>862372954</td>\n",
       "      <td>120404</td>\n",
       "      <td>13962.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 00:04:00+05:00</td>\n",
       "      <td>14010.5</td>\n",
       "      <td>14011.0</td>\n",
       "      <td>13968.5</td>\n",
       "      <td>13972.0</td>\n",
       "      <td>168</td>\n",
       "      <td>4861884435</td>\n",
       "      <td>680351</td>\n",
       "      <td>13993.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp    close     high      low     open  trades  \\\n",
       "0 2018-01-01 00:00:00+05:00  13925.5  13925.5  13892.5  13909.5      93   \n",
       "1 2018-01-01 00:01:00+05:00  13914.0  13938.5  13910.0  13925.5     143   \n",
       "2 2018-01-01 00:02:00+05:00  13960.5  13979.5  13914.0  13914.0     196   \n",
       "3 2018-01-01 00:03:00+05:00  13972.0  13972.0  13950.0  13960.5      76   \n",
       "4 2018-01-01 00:04:00+05:00  14010.5  14011.0  13968.5  13972.0     168   \n",
       "\n",
       "     turnover  volume     vwap  \n",
       "0   934907830  129990  13904.3  \n",
       "1  3584829106  499411  13931.5  \n",
       "2  2916432935  406988  13956.7  \n",
       "3   862372954  120404  13962.6  \n",
       "4  4861884435  680351  13993.8  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp    0.000000\n",
       "close        0.000000\n",
       "high         0.000000\n",
       "low          0.000000\n",
       "open         0.000000\n",
       "trades       0.000000\n",
       "turnover     0.000000\n",
       "volume       0.000000\n",
       "vwap         0.000219\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()/df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date']=df['timestamp'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.groupby('date').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vwap'].replace(0, np.nan, inplace=True)\n",
    "df['vwap'].fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>trades</th>\n",
       "      <th>turnover</th>\n",
       "      <th>volume</th>\n",
       "      <th>vwap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>13541.366319</td>\n",
       "      <td>13557.984028</td>\n",
       "      <td>13524.845139</td>\n",
       "      <td>13541.872917</td>\n",
       "      <td>151.901389</td>\n",
       "      <td>3.191650e+09</td>\n",
       "      <td>430376.524306</td>\n",
       "      <td>13542.399306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>13618.049306</td>\n",
       "      <td>13632.106597</td>\n",
       "      <td>13602.637153</td>\n",
       "      <td>13616.986458</td>\n",
       "      <td>173.356250</td>\n",
       "      <td>3.991163e+09</td>\n",
       "      <td>547527.584028</td>\n",
       "      <td>13618.215833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>14993.412500</td>\n",
       "      <td>15009.243750</td>\n",
       "      <td>14977.330556</td>\n",
       "      <td>14993.340278</td>\n",
       "      <td>188.893056</td>\n",
       "      <td>4.238429e+09</td>\n",
       "      <td>635719.903472</td>\n",
       "      <td>14994.467292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>14846.844444</td>\n",
       "      <td>14859.795139</td>\n",
       "      <td>14833.456944</td>\n",
       "      <td>14846.855556</td>\n",
       "      <td>158.861806</td>\n",
       "      <td>3.806899e+09</td>\n",
       "      <td>564605.880556</td>\n",
       "      <td>14847.653750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>15463.361806</td>\n",
       "      <td>15476.509722</td>\n",
       "      <td>15449.327083</td>\n",
       "      <td>15462.259028</td>\n",
       "      <td>164.459028</td>\n",
       "      <td>3.995719e+09</td>\n",
       "      <td>624329.748611</td>\n",
       "      <td>15464.094653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   close          high           low          open  \\\n",
       "date                                                                 \n",
       "2018-01-01  13541.366319  13557.984028  13524.845139  13541.872917   \n",
       "2018-01-02  13618.049306  13632.106597  13602.637153  13616.986458   \n",
       "2018-01-03  14993.412500  15009.243750  14977.330556  14993.340278   \n",
       "2018-01-04  14846.844444  14859.795139  14833.456944  14846.855556   \n",
       "2018-01-05  15463.361806  15476.509722  15449.327083  15462.259028   \n",
       "\n",
       "                trades      turnover         volume          vwap  \n",
       "date                                                               \n",
       "2018-01-01  151.901389  3.191650e+09  430376.524306  13542.399306  \n",
       "2018-01-02  173.356250  3.991163e+09  547527.584028  13618.215833  \n",
       "2018-01-03  188.893056  4.238429e+09  635719.903472  14994.467292  \n",
       "2018-01-04  158.861806  3.806899e+09  564605.880556  14847.653750  \n",
       "2018-01-05  164.459028  3.995719e+09  624329.748611  15464.094653  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from numpy import array\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM,GRU\n",
    "from sklearn.preprocessing import MinMaxScaler,RobustScaler,StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas import Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df['vwap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps_in\n",
    "\t\tout_end_ix = end_ix + n_steps_out\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif out_end_ix > len(sequence):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# load the dataset\n",
    "dataframe = data\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float64').reshape(-1, 1)\n",
    "\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler()\n",
    "#scaler=RobustScaler()\n",
    "#scaler=StandardScaler()\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "\n",
    "n_steps_in=4\n",
    "n_steps_out=1\n",
    "\n",
    "trainX, trainY =split_sequence(train.flatten(), n_steps_in, n_steps_out)\n",
    "testX, testY = split_sequence(test.flatten(), n_steps_in, n_steps_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 1\n",
    "trainX = trainX.reshape((trainX.shape[0], trainX.shape[1], n_features))\n",
    "testX = testX.reshape((testX.shape[0], testX.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((676, 4, 1), (676, 1), (332, 4, 1), (332, 1))"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape,trainY.shape,testX.shape,testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1124\n",
      "Epoch 2/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0720\n",
      "Epoch 3/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0398\n",
      "Epoch 4/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0219\n",
      "Epoch 5/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0179\n",
      "Epoch 6/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0156\n",
      "Epoch 7/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0132\n",
      "Epoch 8/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0113\n",
      "Epoch 9/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0094\n",
      "Epoch 10/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0076\n",
      "Epoch 11/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0060\n",
      "Epoch 12/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0047\n",
      "Epoch 13/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0036\n",
      "Epoch 14/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0029\n",
      "Epoch 15/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 16/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0021\n",
      "Epoch 17/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0020\n",
      "Epoch 18/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0020\n",
      "Epoch 19/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0019\n",
      "Epoch 20/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0019\n",
      "Epoch 21/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0019\n",
      "Epoch 22/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0019\n",
      "Epoch 23/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0019\n",
      "Epoch 24/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0018\n",
      "Epoch 25/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0018\n",
      "Epoch 26/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0018\n",
      "Epoch 27/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0018\n",
      "Epoch 28/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0018\n",
      "Epoch 29/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0018\n",
      "Epoch 30/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0018\n",
      "Epoch 31/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0017\n",
      "Epoch 32/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0017\n",
      "Epoch 33/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0017\n",
      "Epoch 34/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0017\n",
      "Epoch 35/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0017\n",
      "Epoch 36/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0017\n",
      "Epoch 37/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0017\n",
      "Epoch 38/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0017\n",
      "Epoch 39/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0016\n",
      "Epoch 40/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0016\n",
      "Epoch 41/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0016\n",
      "Epoch 42/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0016\n",
      "Epoch 43/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0016\n",
      "Epoch 44/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0016\n",
      "Epoch 45/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0016\n",
      "Epoch 46/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0016\n",
      "Epoch 47/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0016\n",
      "Epoch 48/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0016\n",
      "Epoch 49/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0016\n",
      "Epoch 50/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0016\n",
      "Epoch 51/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0016\n",
      "Epoch 52/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0016\n",
      "Epoch 53/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0016\n",
      "Epoch 54/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 55/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 56/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 57/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0015\n",
      "Epoch 58/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0015\n",
      "Epoch 59/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0015\n",
      "Epoch 60/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 61/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 62/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 63/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 64/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 65/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 66/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 67/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 68/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 69/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 70/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 71/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0015\n",
      "Epoch 72/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 73/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 74/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 75/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 76/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 77/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 78/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 79/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 80/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 81/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 82/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 83/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0015\n",
      "Epoch 84/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 85/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 86/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 87/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 88/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 89/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 90/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 91/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 92/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 93/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0015\n",
      "Epoch 94/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 95/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 96/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 97/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 98/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 99/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 100/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 101/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 102/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0015\n",
      "Epoch 103/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 104/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 105/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 106/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 107/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 108/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 109/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 110/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 111/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 112/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 113/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 114/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 115/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 116/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 117/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 118/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 119/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 120/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 121/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 122/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 123/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 124/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 125/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 126/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 127/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 128/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 129/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 130/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 131/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 132/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 133/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 134/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 135/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 136/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 137/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 138/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 139/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 140/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 141/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 142/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 143/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 144/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 145/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 146/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 147/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 148/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 149/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 150/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 151/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 152/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 153/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 154/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 155/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 156/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 157/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 158/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 159/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 160/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 161/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 162/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 163/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 164/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 165/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 166/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 167/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 168/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 169/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 170/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 171/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 172/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 173/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 174/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 175/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 176/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 177/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 178/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 179/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 180/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 181/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 182/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 183/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 184/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 185/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 186/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 187/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 188/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 189/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 190/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 191/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 192/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 193/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 194/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 195/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 196/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 197/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 198/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 199/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 200/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 201/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 202/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 203/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 204/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 205/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 206/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 207/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 208/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 209/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 210/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 211/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 212/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 213/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 214/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 215/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 216/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 217/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 218/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 219/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 220/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 221/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 222/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 223/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 224/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 225/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 226/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 227/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 228/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 229/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0010\n",
      "Epoch 230/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0010\n",
      "Epoch 231/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0010\n",
      "Epoch 232/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0010\n",
      "Epoch 233/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0010\n",
      "Epoch 234/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0010\n",
      "Epoch 235/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0010\n",
      "Epoch 236/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 9.9968e-04\n",
      "Epoch 237/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 9.9270e-04\n",
      "Epoch 238/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 9.8568e-04\n",
      "Epoch 239/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 9.7861e-04\n",
      "Epoch 240/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 9.7150e-04\n",
      "Epoch 241/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 9.6435e-04\n",
      "Epoch 242/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 9.5718e-04\n",
      "Epoch 243/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 9.4998e-04\n",
      "Epoch 244/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 9.4276e-04\n",
      "Epoch 245/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 9.3553e-04\n",
      "Epoch 246/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 9.2830e-04\n",
      "Epoch 247/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 9.2106e-04\n",
      "Epoch 248/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 9.1384e-04\n",
      "Epoch 249/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 9.0663e-04\n",
      "Epoch 250/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 8.9944e-04\n",
      "Epoch 251/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 8.9228e-04\n",
      "Epoch 252/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 8.8515e-04\n",
      "Epoch 253/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 8.7807e-04\n",
      "Epoch 254/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 8.7103e-04\n",
      "Epoch 255/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 8.6404e-04\n",
      "Epoch 256/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 8.5710e-04\n",
      "Epoch 257/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 8.5023e-04\n",
      "Epoch 258/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 8.4343e-04\n",
      "Epoch 259/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 8.3669e-04\n",
      "Epoch 260/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 8.3003e-04\n",
      "Epoch 261/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 8.2345e-04\n",
      "Epoch 262/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 8.1695e-04\n",
      "Epoch 263/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 8.1054e-04\n",
      "Epoch 264/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 8.0421e-04\n",
      "Epoch 265/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 7.9798e-04\n",
      "Epoch 266/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 7.9184e-04\n",
      "Epoch 267/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 7.8580e-04\n",
      "Epoch 268/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 7.7985e-04\n",
      "Epoch 269/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 7.7401e-04\n",
      "Epoch 270/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 7.6827e-04\n",
      "Epoch 271/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 7.6264e-04\n",
      "Epoch 272/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 7.5711e-04\n",
      "Epoch 273/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 7.5169e-04\n",
      "Epoch 274/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 7.4638e-04\n",
      "Epoch 275/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 7.4119e-04\n",
      "Epoch 276/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 7.3610e-04\n",
      "Epoch 277/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 7.3113e-04\n",
      "Epoch 278/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 7.2628e-04\n",
      "Epoch 279/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 7.2153e-04\n",
      "Epoch 280/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 7.1691e-04\n",
      "Epoch 281/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 7.1239e-04\n",
      "Epoch 282/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 7.0799e-04\n",
      "Epoch 283/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 7.0371e-04\n",
      "Epoch 284/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 6.9954e-04\n",
      "Epoch 285/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 6.9547e-04\n",
      "Epoch 286/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 6.9152e-04\n",
      "Epoch 287/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 6.8768e-04\n",
      "Epoch 288/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 6.8394e-04\n",
      "Epoch 289/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 6.8031e-04\n",
      "Epoch 290/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 6.7679e-04\n",
      "Epoch 291/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 6.7336e-04\n",
      "Epoch 292/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 6.7003e-04\n",
      "Epoch 293/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 6.6679e-04\n",
      "Epoch 294/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 6.6365e-04\n",
      "Epoch 295/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 6.6060e-04\n",
      "Epoch 296/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 6.5764e-04\n",
      "Epoch 297/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 6.5477e-04\n",
      "Epoch 298/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 6.5197e-04\n",
      "Epoch 299/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 4ms/step - loss: 6.4926e-04\n",
      "Epoch 300/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 6.4662e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5a10e2b550>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Activation, Dense,Dropout\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(15, return_sequences=True,input_shape=(n_steps_in, n_features)))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(LSTM(15))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(n_steps_out))\n",
    "\n",
    "import keras\n",
    "from keras import optimizers\n",
    "\n",
    "#keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False, clipnorm=1)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=300, verbose=1,shuffle=False,batch_size=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((676, 1), (332, 1))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainPredict.shape,testPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform(trainY)\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform(testY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 330.27 RMSE\n",
      "Test Score: 274.21 RMSE\n",
      "                    vwap     predicted\n",
      "date                                  \n",
      "2018-01-01  13542.399306           NaN\n",
      "2018-01-02  13618.215833           NaN\n",
      "2018-01-03  14994.467292           NaN\n",
      "2018-01-04  14847.653750           NaN\n",
      "2018-01-05  15464.094653  14714.563477\n",
      "...                  ...           ...\n",
      "2020-10-08  10682.006324  10707.003906\n",
      "2020-10-09  10945.438985  10754.613281\n",
      "2020-10-10  11274.019792  10998.265625\n",
      "2020-10-11  11361.710069  11336.256836\n",
      "2020-10-12  11376.076368  11455.522461\n",
      "\n",
      "[1016 rows x 2 columns] [4, 330.2661508327778, 274.2103458407201]\n"
     ]
    }
   ],
   "source": [
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY, testPredict))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "predictions = numpy.empty_like(dataset)\n",
    "predictions[:, :] = numpy.nan\n",
    "predictions[n_steps_in:len(trainPredict)+n_steps_in, :] = trainPredict\n",
    "predictions[len(trainPredict)+(n_steps_in*2):len(dataset)+2, :] = testPredict\n",
    "\n",
    "predictionsDF=pd.DataFrame(predictions,columns=[\"predicted\"],index=dataframe.index)\n",
    "ans=pd.concat([dataframe,predictionsDF],axis=1)\n",
    "print( ans,[n_steps_in,trainScore,testScore])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
